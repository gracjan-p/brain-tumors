{ "cells": [  {   "metadata": {},   "cell_type": "markdown",   "source": [    "# Introduction\n",    "In this project we are going to analyze 'brain tumor dataset' T1 weighted images dataset from figshare,\n",    "<br>\n",    "apply some custom functions and Convolutional neural network model that predicts brain tumor type from given image.\n",    "#### This project inludes:\n",    "- Image data analysis\n",    "- Preprocessing data\n",    "- Creating neural network model\n",    "<br>\n",    "\n",    "Highly reccomended to read the **data-description.txt** file to understand data organization."   ],   "id": "ce6d5173c5b31beb"  },  {   "cell_type": "code",   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "end_time": "2024-12-15T20:01:44.155970Z",     "start_time": "2024-12-15T20:01:39.735322Z"    }   },   "source": [    "import tensorflow as tf\n",    "import pandas as pd\n",    "import numpy as np\n",    "import matplotlib.pyplot as plt\n",    "import seaborn as sb\n",    "import cv2 as cv\n",    "import os\n",    "from PIL import Image\n",    "import h5py\n",    "from skimage import exposure"   ],   "outputs": [],   "execution_count": 1  },  {   "metadata": {},   "cell_type": "markdown",   "source": [    "# I Data preview\n",    "#### Step 1 - Image extraction\n",    "We're going to convert .mat files to .jpg files. This process basically had me to look at result folder manually to test the conversion by eye.\n",    "<br><br>\n",    "Preprocessing images:\n",    "1) Exposure\n",    "2) Contrast stretching\n",    "3) Value scaling"   ],   "id": "4cbeb2a05e3169f5"  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2024-12-15T20:01:44.164613Z",     "start_time": "2024-12-15T20:01:44.156973Z"    }   },   "cell_type": "code",   "source": [    "tf.random.set_seed(0)\n",    "mat_path = 'D:\\\\data-science\\\\brain-tumor-data\\\\mat'\n",    "data_path = 'D:\\\\data-science\\\\brain-tumor-data\\\\images'\n",    "label_names = ['meningioma', 'glioma', 'pituitary']\n",    "matrices = os.listdir(mat_path)"   ],   "id": "e9814393f4777cb7",   "outputs": [],   "execution_count": 2  },  {   "metadata": {    "ExecuteTime": {     "end_time": "2024-12-15T20:02:44.676812Z",     "start_time": "2024-12-15T20:02:44.056654Z"    }   },   "cell_type": "code",   "source": [    "for step in range(4):\n",    "    for i, mat in enumerate(matrices[:4]):\n",    "        with h5py.File(f\"{mat_path}\\\\{mat}\", 'r') as file:\n",    "            image = file['cjdata']['image']\n",    "            label = int(file['cjdata']['label'][0]) - 1\n",    "\n",    "            image = np.array(image)\n",    "            \n",    "            # normalize img values where [min, max] = [0, 1] and multiply to [0, 255]\n",    "            image = np.array(image) / np.max(image)\n",    "            image *= 255\n",    "            image = image.astype(np.uint8)\n",    "\n",    "            # 1 increase exposure\n",    "            if step == 1:\n",    "                image = exposure.equalize_hist(image)\n",    "                image *= 255\n",    "                image = image.astype(np.uint8)\n",    "\n",    "            # 2 add contrast stretching\n",    "            if step == 2:\n",    "                image = exposure.equalize_hist(image)\n",    "                image = (image - (image.min())) / (image.max() - (image.min()))\n",    "                image *= 255\n",    "                image = np.array(image).astype(np.uint8)\n",    "\n",    "            # 3 clean background from noise and limit amount of colors\n",    "            if step == 3:                \n",    "                image[image <= 30] = 0\n",    "                \n",    "                image //= 100\n",    "                image *= 100\n",    "                \n",    "                image = exposure.equalize_hist(image)\n",    "                image = (image - (image.min())) / (image.max() - (image.min()))\n",    "                image *= 255\n",    "                \n",    "                # divide array and then multiply it by same number [50, 70, 120] // 100, * 100 => [0, 0, 100]\n",    "\n",    "                image = np.array(image).astype(np.uint8)\n",    "\n",    "            img_values = Image.fromarray(image)\n",    "\n",    "            file_name = label_names[label] + f\"_{i}_{step}.png\"\n",    "            img_values.save(data_path + '\\\\test\\\\' + file_name)"   ],   "id": "b9e8a35c2cdb894f",   "outputs": [    {     "name": "stderr",     "output_type": "stream",     "text": [      "C:\\Users\\ati\\AppData\\Local\\Temp\\ipykernel_12136\\301297995.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",      "  label = int(file['cjdata']['label'][0]) - 1\n"     ]    }   ],   "execution_count": 5  },  {   "metadata": {},   "cell_type": "code",   "source": [    "for i, mat in enumerate(matrices):\n",    "    with h5py.File(f\"{mat_path}\\\\{mat}\", 'r') as file:\n",    "        image = file['cjdata']['image']\n",    "        label = int(file['cjdata']['label'][0]) - 1\n",    "\n",    "        # taking off 'near black' values to reduce background noise\n",    "        image = np.array(image) / np.max(image)\n",    "        image *= 255\n",    "        image[image <= 50] = 0\n",    "\n",    "        # function that fixes exposure\n",    "        image = exposure.equalize_hist(image)\n",    "\n",    "        # add contrast stretching\n",    "        image = (image - (image.min())) / (image.max() - (image.min()))\n",    "        image *= 255\n",    "        \n",    "        image //= 100\n",    "        image *= 100\n",    "\n",    "        image = np.array(image).astype(np.uint8)\n",    "        img_values = Image.fromarray(image)\n",    "\n",    "        file_name = label_names[label] + f\"_{i}.png\"\n",    "        img_values.save(data_path + '\\\\' + label_names[label] + '\\\\' + file_name)\n",    "    # print(f\"{(i + 1) / 3064 * 100} %\")"   ],   "id": "b9ce1266c06eb4ce",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "test_path = 'D:\\\\data-science\\\\brain-tumor-data\\\\test'\n",    "test_files = os.listdir(test_path)\n",    "\n",    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(20, 20))\n",    "\n",    "for i, file in enumerate(test_files):\n",    "    img = Image.open(test_path + '\\\\' + file)\n",    "    y, x = [int(x[0]) for x in file.split('_')[1:]]\n",    "    \n",    "    axes[y, x].imshow(img, cmap='grey', vmin=0, vmax=255)\n",    "    axes[y, x].set_axis_off()\n",    "    axes[y, 0].set_title('original')\n",    "    axes[y, 1].set_title('Added exposure')\n",    "    axes[y, 2].set_title('Contrast stretched')\n",    "    axes[y, 3].set_title('Cleaned background')\n",    "\n",    "plt.tight_layout()"   ],   "id": "7d63d10063a10a9f",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "data = tf.keras.utils.image_dataset_from_directory(data_path, batch_size=8, color_mode='grayscale', image_size=(512, 512))\n",    "label_names = data.class_names\n",    "print(f\"Labels: {label_names}\\n\")"   ],   "id": "4ad911855cf3689",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "data_iterator = data.as_numpy_iterator()\n",    "batch = data_iterator.next()"   ],   "id": "998c69db719e8b80",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(24, 6))\n",    "for i, img in enumerate(batch[0][:8]):\n",    "    class_name = label_names[batch[1][i]]\n",    "    axes[i].imshow(img, cmap='gray')\n",    "    axes[i].set_title(class_name)\n",    "    axes[i].set_axis_off()\n",    "\n",    "plt.tight_layout()\n",    "plt.show()"   ],   "id": "da96026cc61d92d7",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "files_per_label = lambda x: os.listdir(data_path + '\\\\' + x)\n",    "\n",    "labels_len = {label: len(files_per_label(label)) for label in label_names}\n",    "\n",    "sb.barplot(data=labels_len, x=labels_len.keys(), y=labels_len.values(), color='Black')\n",    "\n",    "for label in label_names:\n",    "    print(f\"{label:>10}: {len(os.listdir(f\"{data_path}\\\\{label}\"))}\")\n",    "    \n",    "plt.show()"   ],   "id": "fe8984647a9cba57",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "markdown",   "source": [    "Our dataset contains 512px x 512px images and each pixel has 3 channels so basically each image contains **786 432** values,\n",    "<br>\n",    "by using *color_mode = 'grayscale'* we reduce it to **262 144**. Also keras resized our files to size of 256px x 256px so we end up with **65 536** values per image.\n",    "<br><br>\n",    "I tested downsampling by removing random files from glioma and pituitary folders. However it didn't help at all, it even dropped accuracy by almost 10%."   ],   "id": "1ead899c32b202a8"  },  {   "metadata": {},   "cell_type": "markdown",   "source": [    "# II Feature scaling\n",    "Scaling our values from range (0, 255) to (0, 1) will help our optimization algorithm (Adam).\n",    "<br><br>\n",    "x = image values\n",    "<br> \n",    "y = labels"   ],   "id": "c575ba9dbd4fe2e4"  },  {   "metadata": {},   "cell_type": "code",   "source": "print(batch[0].min(), batch[0].max(), sep='\\n')",   "id": "78e8d990deb7810c",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": "data = data.map(lambda x, y: (x/255, y))",   "id": "6de18c47e54f6856",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "iterator = data.as_numpy_iterator()\n",    "batch = iterator.next()\n",    "\n",    "min_value = iterator.next()[0].min()\n",    "max_value = iterator.next()[0].max()\n",    "\n",    "print(min_value, max_value, sep='\\n')"   ],   "id": "e06d659a0379e156",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "markdown",   "source": [    "Checking black/white balance in images. For selecting reference point on scale I used harmonic mean because it favortise lower values.\n",    "<br>\n",    "Every point on the plot is a single image, we can see that most of images hang around ratio of 0.19"   ],   "id": "f4b7551f69f1c815"  },  {   "metadata": {},   "cell_type": "code",   "source": [    "from scipy.stats.mstats import hmean\n",    "\n",    "all_images = []\n",    "for images, label in data:\n",    "    all_images.append(images.numpy())\n",    "\n",    "all_images = np.concatenate(all_images, axis=0)\n",    "# skipping value 0 because it's background and it will lower our mean\n",    "all_means = [x[x != 0].mean() for x in all_images]\n",    "\n",    "print(f'{'Mean':>14}: {np.mean(all_means)}\\n'\n",    "      f'{'Harmonic mean':>14}: {hmean(all_means)}')\n",    "\n",    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(20, 10))\n",    "sb.scatterplot(y=[x for x in range(len(all_means))], x=all_means, color='black', s=5, ax=axes[0])\n",    "sb.kdeplot(x=all_means, color='black', ax=axes[1])\n",    "plt.tight_layout()"   ],   "id": "3aac453546168148",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "markdown",   "source": "###### THIS FUNCTION WAS USED IN OLD DATASET WHERE MEAN VALUES WERE SPREAD MORE",   "id": "d93d91d5a699f6f7"  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def scale_to_target(batch, target=0.5, multiplier=1):\n",    "    f\"\"\"\n",    "    This function scales image values inside given array to achieve mean value that equals target value.\\n\n",    "    mean of array => target\\n\n",    "    array - the array to be scaled\\n\n",    "    target - value that we want our mean of given array to become\\n\n",    "    multiplier - % of effect, 0.5 is basically mean of our array mean and target value\n",    "    \"\"\"\n",    "    def scale_single_image(img):\n",    "        current_mean = tf.reduce_mean(img)\n",    "        new_mean = current_mean + (multiplier * (target - current_mean))\n",    "        scale_factor = new_mean / current_mean if current_mean != 0 else tf.cast(0, dtype=new_mean.dtype)\n",    "        return img * scale_factor\n",    "\n",    "    scaled_batch = tf.map_fn(scale_single_image, batch)\n",    "    return scaled_batch"   ],   "id": "3d42f4e8c4dc8917",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "markdown",   "source": [    "# III Creating CNN Model\n",    "- In short convolutional neural network base on layers that convolve input matrix (image) through filter matrices resulting filtered output.\n",    "<br>\n",    "- As input shape we apply values that corresponds to:\n",    "    - width = 256\n",    "    - height = 256\n",    "    - channel = 1 (we use grayscaled images).\n",    "<br>\n",    "- __*ReLU*__ activation function cleans our output from all unecesary negative values, replacing them with zeros that came from filter multiplication.\n",    "<br>\n",    "- Since our dataset contain 4 classes I applied __*softmax*__ activation to last step."   ],   "id": "c185ba1b583906e9"  },  {   "metadata": {},   "cell_type": "code",   "source": [    "train_batch_size = round(len(data) * 0.7)\n",    "val_batch_size = round(len(data) * 0.2)\n",    "test_batch_size = round(len(data) * 0.1) + 1\n",    "\n",    "len(data) == train_batch_size + val_batch_size + test_batch_size"   ],   "id": "2be0de620e4f654b",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "train = data.take(train_batch_size)\n",    "val = data.skip(train_batch_size).take(val_batch_size)\n",    "test = data.skip(train_batch_size + val_batch_size).take(test_batch_size)\n",    "\n",    "print(\n",    "    f\"train: {len(train)} batches\\nval: {len(val)} batches\\ntest: {len(test)} batches\"\n",    ")"   ],   "id": "b03cfc99ee8aa005",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "from tensorflow.keras.models import Sequential\n",    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Input\n",    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",    "from tensorflow.keras.optimizers import Adam"   ],   "id": "1d90ad011535634f",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "def create_model(num_filters = 16, kernel_size = 3, learning_rate = 0, regulate = 0):\n",    "    \n",    "    model = Sequential()\n",    "    \n",    "    model.add(Input(shape=(512, 512, 1)))\n",    "    \n",    "    model.add(Conv2D(num_filters, (kernel_size, kernel_size), 1, activation='relu'))\n",    "    model.add(MaxPooling2D())\n",    "    \n",    "    model.add(Conv2D(num_filters*2, (kernel_size, kernel_size), 1, activation='relu'))\n",    "    model.add(MaxPooling2D())\n",    "    \n",    "    model.add(Conv2D(num_filters, (kernel_size, kernel_size), 1, activation='relu'))\n",    "    model.add(MaxPooling2D())\n",    "    \n",    "    model.add(Flatten())\n",    "    model.add(Dense(512, activation='relu'))\n",    "    model.add(Dropout(0.5))\n",    "    model.add(Dense(3, activation='softmax'))\n",    "    \n",    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",    "    \n",    "    return model"   ],   "id": "6ac59857ba8082fd",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "model = create_model(learning_rate=0.0001)\n",    "model.summary()"   ],   "id": "fbb8761adbf688de",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": "callback_board = tf.keras.callbacks.TensorBoard('data_processed_imgs')",   "id": "b1f88b742b17608e",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[callback_board])",   "id": "600242a8da3acfdb",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "acc_labels = list(hist.history.keys())\n",    "\n",    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",    "for i in range(4):\n",    "    fig = sb.lineplot(y=hist.history[acc_labels[i]], x=[x for x in range(1, 11, 1)], label=acc_labels[i], ax=axes[i//2])\n",    "    axes[i//2].legend(loc='lower right', bbox_to_anchor=(1.005, 1), ncol=2)\n",    "\n",    "axes[0].set_title('Train')\n",    "axes[0].set_xlabel('Epoch')\n",    "axes[0].set_xlim([1, 10])\n",    "\n",    "axes[1].set_title('Validation')\n",    "axes[1].set_xlabel('Epoch')\n",    "axes[1].set_xlim([1, 10])\n",    "\n",    "plt.tight_layout()"   ],   "id": "786872f94a5dcbaf",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "y_true = []\n",    "y_pred = []\n",    "\n",    "for batch_images, batch_labels in test:\n",    "    y_true_batch = batch_labels\n",    "    y_pred_batch = np.argmax(model.predict(batch_images, verbose=0), axis=1)\n",    "\n",    "    y_true.extend(y_true_batch)\n",    "    y_pred.extend(y_pred_batch)"   ],   "id": "64bfbf5933fe5a6",   "outputs": [],   "execution_count": null  },  {   "metadata": {},   "cell_type": "code",   "source": [    "from sklearn.metrics import classification_report, confusion_matrix\n",    "\n",    "report = classification_report(y_true, y_pred, target_names=label_names)\n",    "print(report)\n",    "\n",    "cm = confusion_matrix(y_true=y_true, y_pred=y_pred)\n",    "fig = plt.figure(figsize=(5, 5))\n",    "fig = sb.heatmap(cm, annot=True, fmt='d', cbar=False, cmap='Greys')\n",    "plt.xlabel('Predicted')\n",    "plt.ylabel('True')\n",    "plt.tight_layout()"   ],   "id": "84511b1b78ccd230",   "outputs": [],   "execution_count": null  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}