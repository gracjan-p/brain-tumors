{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(data_path_after, batch_size=8, color_mode='grayscale', image_size=(256, 256))\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()"
   ],
   "id": "c5385d79c9aa6912",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=8, figsize=(24, 6))\n",
    "for i, img in enumerate(batch[0][:8]):\n",
    "    class_name = labels[batch[1][i]]\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].set_title(class_name)\n",
    "    axes[i].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ae64dc200ed7d512"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**_deprecated_**\n",
    "<br>\n",
    "The process below is called _color quantization_.\n",
    "<br>\n",
    "For this task I used Kmeans algorithm to cluster color values in each image.\n",
    "<br>\n",
    "So instead of dealing with 255 shades of grey we have only 5 colors per image. "
   ],
   "id": "a97e2e01ad12826f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import cv2 as cv\n",
    "\n",
    "all_files = lambda label: os.listdir(os.path.join(data_path, label))\n",
    "\n",
    "_ = 0\n",
    "for label in labels:\n",
    "    break\n",
    "    for i, file in enumerate(all_files(label)):\n",
    "        \n",
    "        # if _ >= 10:\n",
    "        #     break\n",
    "            \n",
    "        file_path = os.path.join(data_path, label, file)\n",
    "\n",
    "        img = cv.imread(file_path, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "        width, height = img.shape[0], img.shape[1]\n",
    "\n",
    "        reshaped_image = np.reshape(img, (width * height, 1))\n",
    "\n",
    "        kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "        target = kmeans.fit_predict(reshaped_image)\n",
    "        color_space = kmeans.cluster_centers_\n",
    "        \n",
    "        img_after = np.reshape(color_space[target], img.shape)\n",
    "        \n",
    "        cv.imwrite(os.path.join(data_path_after, label, f\"{label}_{i}.png\"), img_after)\n",
    "\n",
    "print('Done!')"
   ],
   "id": "9dda9b9abfd63673",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import splitfolders\n",
    "\n",
    "input_folder = \"D:\\\\data-science\\\\brain-tumor-data\\\\processed_images\"\n",
    "output_folder = \"D:\\\\data-science\\\\brain-tumor-data\\\\processed_images_split\"\n",
    "\n",
    "splitfolders.ratio(input=input_folder, output=output_folder, ratio=(.7, .2, .1))"
   ],
   "id": "fe3fddf504d35e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T20:35:47.998846Z",
     "start_time": "2024-12-27T20:35:43.353770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_path = 'D:\\\\data-science\\\\brain-tumor-data\\\\images'\n",
    "data_path_split = data_path + '_split'\n",
    "\n",
    "test = tf.keras.utils.image_dataset_from_directory(os.path.join(data_path_split, 'test'), batch_size=8, color_mode='grayscale', image_size=(256, 256))\n",
    "label_names = test.class_names\n",
    "# val = tf.keras.utils.image_dataset_from_directory(os.path.join(data_path_split, 'val'), batch_size=8, color_mode='grayscale', image_size=(256, 256))\n",
    "test = test.map(lambda x, y: (x/255, y))\n",
    "model = tf.keras.models.load_model(\"tumor-type-cnn-v1.h5\")"
   ],
   "id": "e9a55b01e23bf590",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T20:35:48.004896Z",
     "start_time": "2024-12-27T20:35:48.000850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Recompile the model with metrics\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# Now you can evaluate or train the model\n",
    "# model.evaluate(val)"
   ],
   "id": "17eefddb3344d705",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T20:35:51.862833Z",
     "start_time": "2024-12-27T20:35:48.005900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for imgs, labels in test:\n",
    "    batch_predictions = model.predict(imgs, verbose=0)\n",
    "    \n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend(batch_predictions)\n",
    "\n",
    "# y_true = np.concatenate(y_true, axis=0)\n",
    "# y_pred = np.concatenate(y_pred, axis=0)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ],
   "id": "84a45adfaef81559",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T20:35:52.017640Z",
     "start_time": "2024-12-27T20:35:51.863836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=label_names)\n",
    "print(report)"
   ],
   "id": "45769423a598e265",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.97      0.98      0.97       143\n",
      "  meningioma       0.95      0.86      0.91        72\n",
      "   pituitary       0.94      0.99      0.96        93\n",
      "\n",
      "    accuracy                           0.95       308\n",
      "   macro avg       0.95      0.94      0.95       308\n",
      "weighted avg       0.95      0.95      0.95       308\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
